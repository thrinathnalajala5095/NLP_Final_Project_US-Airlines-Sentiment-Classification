{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936574f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\vseel2\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: regex in c:\\users\\vseel2\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\vseel2\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vseel2\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\vseel2\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1cfb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries & packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d36ae9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the US Airline Sentiment data\n",
    "data_frame = pd.read_csv('Tweets.csv')\n",
    "df = data_frame.copy(deep=True)\n",
    "data_frame.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b455ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3538735f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    9178\n",
       "0    3099\n",
       "1    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#repalcing the categorical values of 'airline_sentiment' to numeric values\n",
    "data_frame['airline_sentiment'].replace(('neutral', 'positive', 'negative'), (0, 1, 2), inplace=True)\n",
    "data_frame['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e3aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming the feature & label variables\n",
    "data = data_frame['text'].values.tolist()\n",
    "labels = data_frame['airline_sentiment'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03dc0592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 11712\n",
      "Number of testing examples: 2928\n"
     ]
    }
   ],
   "source": [
    "#splitting the data into 80 and 20 split\n",
    "train_X, test_X, y_train, y_test = train_test_split(data, labels, test_size=0.2, \n",
    "                                                    random_state=42, shuffle=True)\n",
    "\n",
    "print(f'Number of training examples: {len(train_X)}')\n",
    "print(f'Number of testing examples: {len(test_X)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0e0b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a default pattern for tokenization\n",
    "default_pattern =  r\"\"\"(?x)                  \n",
    "                        (?:[A-Z]\\.)+          \n",
    "                        |\\$?\\d+(?:\\.\\d+)?%?    \n",
    "                        |\\w+(?:[-']\\w+)*      \n",
    "                        |\\.\\.\\.               \n",
    "                        |(?:[.,;\"'?():-_`])    \n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5a8f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion for tokenizing the data\n",
    "\"\"\" Tokenize sentence with specific pattern\n",
    "Arguments: text {str} -- sentence to be tokenized, such as \"I love NLP\"\n",
    "Keyword Arguments: pattern {str} -- reg-expression pattern for tokenizer (default: {default_pattern})\n",
    "Returns: list -- list of tokenized words, such as ['I', 'love', 'nlp'] \"\"\"\n",
    "def tokenize(text, pattern = default_pattern):\n",
    "\n",
    "  text = text.lower()\n",
    "  return regexp_tokenize(text, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "191690c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize training text into tokens\n",
    "tokenized_text = []\n",
    "for i in range(0, len(train_X)):\n",
    "    tokenized_text.append(tokenize(train_X[i]))\n",
    "\n",
    "X_train = tokenized_text\n",
    "\n",
    "# Tokenize testing text into tokens\n",
    "tokenized_text = []\n",
    "for i in range(0, len(test_X)):\n",
    "    tokenized_text.append(tokenize(test_X[i]))\n",
    "\n",
    "X_test = tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f178878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', 'united', 'you', 'are', 'offering', 'us', '8', 'rooms', 'for', '32', 'people', 'fail'] ['@', 'jetblue', 'jfk', 'nyc', 'staff', 'is', 'amazing', '.', 'the', 'lax', 'jetblue', '...', 'sending', 'an', 'email', 'with', 'details', 'but', 'it', 'was', 'a', 'disappointing', 'experience', '@', 'jetbluecheeps']\n",
      "['@', 'southwestair', \"you're\", 'my', 'early', 'frontrunner', 'for', 'best', 'airline', 'oscars2016']\n"
     ]
    }
   ],
   "source": [
    "#tokenized train & test data\n",
    "print(X_train[0], X_train[1])\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f97d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building dictionary\n",
    "def createDictionary(data):\n",
    "  \"\"\" Function: To create a dictionary of tokens from the data\n",
    "  Arguments: data in the type - list\n",
    "  Returns: Sorted dictionary of the tokens and their count in the data \"\"\"\n",
    "\n",
    "  dictionary = dict()\n",
    "  for sample in  data:\n",
    "    for token in sample:\n",
    "      dictionary[token] = dictionary.get(token, 0) + 1\n",
    "  #sorting the dictionary based on the values\n",
    "  sorted_dict = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "  return dict(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6113b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 tokens in the training dictionary:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('@', 13290),\n",
       " ('.', 12534),\n",
       " ('to', 6858),\n",
       " ('the', 4856),\n",
       " ('i', 4385),\n",
       " ('?', 3729),\n",
       " ('a', 3619),\n",
       " (',', 3354),\n",
       " ('united', 3338),\n",
       " ('you', 3284)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bog = createDictionary(X_train)\n",
    "#top 10 items in the dictionary\n",
    "print(\"Top 10 tokens in the training dictionary:\\n\")\n",
    "list(bog.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41e7ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Navie Bayes Classifier \n",
    "class NBClassifier:\n",
    "\n",
    "    def __init__(self, X_train, y_train, size):\n",
    "      tz_NY = pytz.timezone('America/New_York') \n",
    "      print(\"Model Start Time:\", datetime.now(tz_NY).strftime(\"%H:%M:%S\"))\n",
    "      self.X_train = X_train\n",
    "      self.y_train = y_train\n",
    "      self.size = size\n",
    "\n",
    "    def createDictionary(self):\n",
    "      \"\"\" Function: To create a dictionary of tokens from the data\n",
    "      Arguments: data in the type - list\n",
    "      Returns: Sorted dictionary of the tokens and their count in the data \"\"\"\n",
    "      dictionary = dict()\n",
    "      for sample in  X_train:\n",
    "        for token in sample:\n",
    "          dictionary[token] = dictionary.get(token, 0) + 1\n",
    "      #sorting the dictionary based on the values\n",
    "      sorted_dict = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "      return dict(sorted_dict)\n",
    "    \n",
    "    def fit(self):\n",
    "      \"\"\" Function: To compute the count of words in training data dictionary\n",
    "        Arguments: Trianing data & Size of dictionary\n",
    "        Returns: dictionary of tokens with their class wise probabilities \"\"\"\n",
    "      \n",
    "      X_train_dict = self.createDictionary()\n",
    "      if self.size == 'full':\n",
    "        self.words_list = list(X_train_dict.keys())\n",
    "        self.words_count = dict.fromkeys(self.words_list, None)\n",
    "      else:\n",
    "        self.words_list = list(X_train_dict.keys())[:int(self.size)]\n",
    "        self.words_count = dict.fromkeys(self.words_list, None)\n",
    "            \n",
    "      #DataFrame of training data\n",
    "      train = pd.DataFrame(columns = ['X_train', 'y_train'])\n",
    "      train['X_train'] = X_train\n",
    "      train['y_train'] = y_train\n",
    "\n",
    "      train_0 = train.copy()[train['y_train'] == 0]\n",
    "      train_1 = train.copy()[train['y_train'] == 1]\n",
    "      train_2 = train.copy()[train['y_train'] == 2]\n",
    "\n",
    "      #computing the prior of each class\n",
    "      Pr0 = train_0.shape[0]/train.shape[0]\n",
    "      Pr1 = train_1.shape[0]/train.shape[0]\n",
    "      Pr2 = train_2.shape[0]/train.shape[0]\n",
    "      \n",
    "      self.Prior = np.array([Pr0, Pr1, Pr2])\n",
    "        \n",
    "      #converting list of lists into a list\n",
    "      def flatList(listOfList):\n",
    "        flatten = []\n",
    "        for elem in listOfList:\n",
    "          flatten.extend(elem)\n",
    "        return flatten\n",
    "  \n",
    "      #Creating the data list for each class - tokens of each class\n",
    "      X_train_0 = flatList(train[train['y_train'] == 0]['X_train'].tolist())\n",
    "      X_train_1 = flatList(train[train['y_train'] == 1]['X_train'].tolist())\n",
    "      X_train_2 = flatList(train[train['y_train'] == 2]['X_train'].tolist())\n",
    "    \n",
    "      self.X_train_len = np.array([len(X_train_0), len(X_train_1), len(X_train_2)])\n",
    "\n",
    "      for token in self.words_list:\n",
    "        #list to store three word counts of a token\n",
    "        res = []\n",
    "\n",
    "        #inserting count of token in class 0: Neutral\n",
    "        res.insert(0, X_train_0.count(token))\n",
    "\n",
    "        #inserting count of token in class 1: Positive\n",
    "        res.insert(1, X_train_1.count(token))\n",
    "\n",
    "          #inserting count of token in class 2: Negative\n",
    "        res.insert(2, X_train_2.count(token))\n",
    "\n",
    "        #assigning the count list to its token in the dictionary \n",
    "        self.words_count[token] = res\n",
    "      return self\n",
    "\n",
    "    def predict(self, X_test):\n",
    "      \"\"\" Function: Predicts the label of the data\n",
    "        Arguments: self and the test data\n",
    "        Returns: List of predicted labels for the test data \"\"\"     \n",
    "      pred = []\n",
    "      for sample in X_test:\n",
    "        mul = np.array([1,1,1])\n",
    "        for tokens in sample:\n",
    "          vocab_count = len(self.words_list)\n",
    "          if tokens in self.words_list:\n",
    "            prob = ((np.array(self.words_count[tokens])+1) / (self.X_train_len + vocab_count))\n",
    "          #except:\n",
    "            #prob = ((np.array([0,0,0])+1) / (self.X_train_len + vocab_count))\n",
    "          mul = mul * prob\n",
    "        val = mul * self.Prior\n",
    "        pred.append(np.argmax(val))\n",
    "      tz_NY = pytz.timezone('America/New_York') \n",
    "      print(\"Model End Time:\", datetime.now(tz_NY).strftime(\"%H:%M:%S\"))\n",
    "      return pred\n",
    "    \n",
    "    def score(self, pred, labels):\n",
    "      \"\"\" Function: To compute the perfoemance of the model\n",
    "        Arguments: self, predicted labels and actual labels of the test data\n",
    "        Returns: Number of lables correctly predicted and the accuracy of the model \"\"\"\n",
    "      correct = (np.array(pred) == np.array(labels)).sum()\n",
    "      accuracy = correct/len(pred)\n",
    "      return correct, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "918b29cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating holders to store the model performance results\n",
    "attributes = []\n",
    "corr = []\n",
    "acc = []\n",
    "\n",
    "#function to call for storing the results\n",
    "def storeResults(attr, cor,ac):\n",
    "  attributes.append(attr)\n",
    "  corr.append(round(cor, 3))\n",
    "  acc.append(round(ac, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "538939a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:10:09\n",
      "Model End Time: 15:11:48\n",
      "NBClassifier Model miss any prediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the classifier     \n",
    "nb = NBClassifier(X_train, y_train, 'full')  \n",
    "nb.fit()\n",
    "\n",
    "#predicting the labels for test samples\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "#Checking\n",
    "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eae71566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2291\n",
      "Accuracy of the model: 2291 / 2928 = 0.7824 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor1, acc1 = nb.score(y_pred, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor1)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor1, len(y_pred), acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08282388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('Unprocessed Data', cor1, acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee8efd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#string of punctiations\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "298ba243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the punctuation\n",
    "'''Function: Removes the punctuation from the tokens\n",
    "   Arguments: list of text data samples\n",
    "   Returns: list of tokens of each sample without punctuation '''\n",
    "def removePunctuation(data):\n",
    "    update = []\n",
    "    for sample in data:\n",
    "        #removing punctuation from the tokens\n",
    "        re_punct = [''.join(char for char in word if char not in string.punctuation) for word in sample]\n",
    "        #removes the empty strings\n",
    "        re_punct = [word for word in re_punct if word]\n",
    "       \n",
    "        update.append(re_punct)\n",
    "    return update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b0e1467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['united', 'you', 'are', 'offering', 'us', '8', 'rooms', 'for', '32', 'people', 'fail']\n",
      "['southwestair', 'youre', 'my', 'early', 'frontrunner', 'for', 'best', 'airline', 'oscars2016']\n"
     ]
    }
   ],
   "source": [
    "#Removing punctuation from training data text tokens  \n",
    "X_train_P = removePunctuation(X_train)\n",
    "\n",
    "#Removing punctuation from testing data text tokens\n",
    "X_test_P = removePunctuation(X_test)\n",
    "\n",
    "#train & test data after removing punctuation\n",
    "print(X_train_P[0])\n",
    "print(X_test_P[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49a71dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:11:48\n",
      "Model End Time: 15:13:33\n",
      "NBClassifier Model miss any prediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the classifier     \n",
    "nb_punct = NBClassifier(X_train_P, y_train, 'full')\n",
    "nb_punct.fit()\n",
    "\n",
    "#predicting the labels for test samples\n",
    "y_pred_P = nb_punct.predict(X_test_P)\n",
    "\n",
    "#Checking\n",
    "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7946c582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2285\n",
      "Accuracy of the model: 2285 / 2928 = 0.7804 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor2, acc2 = nb_punct.score(y_pred_P, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor2)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor2, len(y_pred_P), acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "882756cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('No Punctuation Data', cor2, acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e02ed569",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function: Removes the stopwords from the tokens\n",
    "   Arguments: list of text data samples\n",
    "   Returns: list of tokens of each sample without punctuation '''\n",
    "def removeStopWords(data):\n",
    "    update = []\n",
    "    stopwords = ['the', 'at','i', 'of', 'us', 'have', 'a', 'you','ours', 'themselves', \n",
    "                 'that', 'this', 'be', 'is', 'for']\n",
    "    for sample in data:\n",
    "        #removing stopwords from tokenized data\n",
    "        re_stop = [word for word in sample if word not in stopwords]\n",
    "        \n",
    "        update.append(re_stop)\n",
    "    return update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3e60df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', 'united', 'are', 'offering', '8', 'rooms', '32', 'people', 'fail']\n",
      "['@', 'southwestair', \"you're\", 'my', 'early', 'frontrunner', 'best', 'airline', 'oscars2016']\n"
     ]
    }
   ],
   "source": [
    "#Removing stopwords from training data text tokens  \n",
    "X_train_S = removeStopWords(X_train)\n",
    "\n",
    "#Removing stopwords from testing data text tokens\n",
    "X_test_S = removeStopWords(X_test)\n",
    "\n",
    "#train & test data after removing stopwords\n",
    "print(X_train_S[0])\n",
    "print(X_test_S[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a96bb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:13:34\n",
      "Model End Time: 15:15:07\n",
      "NBClassifier Model miss any prediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the classifier     \n",
    "nb_stop = NBClassifier(X_train_S, y_train, 'full')\n",
    "nb_stop.fit()\n",
    "\n",
    "#predicting the labels for test samples\n",
    "y_pred_S = nb_stop.predict(X_test_S)\n",
    "\n",
    "#Checking\n",
    "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1879ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2300\n",
      "Accuracy of the model: 2300 / 2928 = 0.7855 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor3, acc3 = nb_stop.score(y_pred_S, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor3)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor3, len(y_pred_S), acc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "387ebf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('Removed few Stopwords', cor3, acc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "358c08d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['united', 'are', 'offering', '8', 'rooms', '32', 'people', 'fail']\n",
      "['southwestair', 'youre', 'my', 'early', 'frontrunner', 'best', 'airline', 'oscars2016']\n"
     ]
    }
   ],
   "source": [
    "#Removing stopwords from training data text tokens  \n",
    "X_train_PS = removeStopWords(X_train_P)\n",
    "\n",
    "#Removing stopwords from testing data text tokens\n",
    "X_test_PS = removeStopWords(X_test_P)\n",
    "\n",
    "#train & test data after removing stopwords\n",
    "print(X_train_PS[0])\n",
    "print(X_test_PS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fbf1c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:15:07\n",
      "Model End Time: 15:16:42\n",
      "NBClassifier Model miss any prediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the classifier     \n",
    "nb_PS = NBClassifier(X_train_PS, y_train, 'full')\n",
    "nb_PS.fit()\n",
    "\n",
    "#predicting the labels for test samples\n",
    "y_pred_PS = nb_PS.predict(X_test_PS)\n",
    "\n",
    "#Checking\n",
    "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_PS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6862b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2283\n",
      "Accuracy of the model: 2283 / 2928 = 0.7797 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor4, acc4 = nb_PS.score(y_pred_PS, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor4)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor4, len(y_pred_PS), acc4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "611205da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('Removed both Punctuation & Few Stopwords', cor4, acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec69cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in the dictionary: 13606\n"
     ]
    }
   ],
   "source": [
    "#total tokens in training dictionary\n",
    "print('Total tokens in the dictionary:', len(bog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c01d99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:16:42\n",
      "Model End Time: 15:17:13\n",
      "NBClassifier Model miss any prediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the classifier - 5000 tokens \n",
    "nb_5k = NBClassifier(X_train, y_train, '5000')\n",
    "nb_5k.fit()\n",
    "\n",
    "#predicting the labels for test samples\n",
    "y_pred_5k = nb_5k.predict(X_test)\n",
    "\n",
    "#Checking\n",
    "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_5k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb95ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2332\n",
      "Accuracy of the model: 2332 / 2928 = 0.7964 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor5, acc5 = nb_5k.score(y_pred_5k, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor5)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor5, len(y_pred), acc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e64955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('5k Tokens of Voab - Unprocessed Data', cor5, acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "605f4ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:17:13\n",
      "Model End Time: 15:17:51\n",
      "NBClassifier Model miss any prediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the classifier - 5000 tokens \n",
    "nb_5k_P = NBClassifier(X_train_P, y_train, '5000')\n",
    "nb_5k_P.fit()\n",
    "\n",
    "#predicting the labels for test samples\n",
    "y_pred_5k_P = nb_5k_P.predict(X_test_P)\n",
    "\n",
    "#Checking\n",
    "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_5k_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df2a3064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2309\n",
      "Accuracy of the model: 2309 / 2928 = 0.7886 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor6, acc6 = nb_5k.score(y_pred_5k_P, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor6)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor6, len(y_pred), acc6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6b0aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('5k Tokens of Voab - No Punctuation Data', cor6, acc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a001ed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:17:51\n",
      "Model End Time: 15:18:25\n",
      "NBClassifier Model miss any prediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the classifier - 5000 tokens \n",
    "nb_5k_S = NBClassifier(X_train_S, y_train, '5000')\n",
    "nb_5k_S.fit()\n",
    "\n",
    "#predicting the labels for test samples\n",
    "y_pred_5k_S = nb_5k_S.predict(X_test_S)\n",
    "\n",
    "#Checking\n",
    "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_5k_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bdf2447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2321\n",
      "Accuracy of the model: 2321 / 2928 = 0.7927 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor7, acc7 = nb_5k_S.score(y_pred_5k_S, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor7)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor7, len(y_pred), acc7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3fc35f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('5k Tokens of Voab - Removed few Stopwords', cor7, acc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb9bfa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:18:26\n",
      "Model End Time: 15:18:59\n",
      "NBClassifier Model miss any prediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the classifier - 5000 tokens \n",
    "nb_5k_PS = NBClassifier(X_train_PS, y_train, '5000')\n",
    "nb_5k_PS.fit()\n",
    "\n",
    "#predicting the labels for test samples\n",
    "y_pred_5k_PS = nb_5k_PS.predict(X_test_PS)\n",
    "\n",
    "#Checking\n",
    "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_5k_PS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79d32683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2296\n",
      "Accuracy of the model: 2296 / 2928 = 0.7842 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor8, acc8 = nb_5k_PS.score(y_pred_5k_PS, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor8)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor8, len(y_pred), acc8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34c350ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('5k Tokens of Voab - Removed both Punctuation & Few Stopwords', cor8, acc8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58ed829c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:18:59\n",
      "Model End Time: 15:19:42\n",
      "NBClassifier Model miss any prediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the classifier - 5000 tokens \n",
    "nb_10k = NBClassifier(X_train, y_train, '5000')\n",
    "nb_10k.fit()\n",
    "\n",
    "#predicting the labels for test samples\n",
    "y_pred_10k = nb_10k.predict(X_test)\n",
    "\n",
    "#Checking\n",
    "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_10k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d78b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2332\n",
      "Accuracy of the model: 2332 / 2928 = 0.7964 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor9, acc9 = nb_10k.score(y_pred_10k, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor9)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor9, len(y_pred), acc9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6ddd384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('10k Tokens of Voab - Unprocessed Data', cor9, acc9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a38672a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:19:42\n",
      "Model End Time: 15:20:56\n",
      "NBClassifier Model miss any prediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the classifier - 10000 tokens \n",
    "nb_10k_P = NBClassifier(X_train_P, y_train, '10000')\n",
    "nb_10k_P.fit()\n",
    "\n",
    "#predicting the labels for test samples\n",
    "y_pred_10k_P = nb_10k_P.predict(X_test_P)\n",
    "  \n",
    "#Checking\n",
    "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_10k_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb2066a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2287\n",
      "Accuracy of the model: 2287 / 2928 = 0.7811 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor10, acc10 = nb_10k_P.score(y_pred_10k_P, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor10)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor10, len(y_pred), acc10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d6b292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('10k Tokens of Voab - No Punctuation Data', cor10, acc10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aebd3138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:20:56\n",
      "Model End Time: 15:22:10\n",
      "NBClassifier Model miss any Srediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the classifier - 10000 tokens \n",
    "nb_10k_S = NBClassifier(X_train_S, y_train, '10000')\n",
    "nb_10k_S.fit()\n",
    "\n",
    "#Sredicting the labels for test samSles\n",
    "y_pred_10k_S = nb_10k_S.predict(X_test_S)\n",
    "  \n",
    "#Checking\n",
    "print(\"NBClassifier Model miss any Srediction???\", len(X_test) != len(y_pred_10k_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59a3c3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2321\n",
      "Accuracy of the model: 2321 / 2928 = 0.7927 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor11, acc11 = nb_10k_S.score(y_pred_10k_S, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor11)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor11, len(y_pred), acc11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfd1ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('10k Tokens of Voab - Removed few Stopwords', cor11, acc11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af8e3a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Start Time: 15:22:10\n",
      "Model End Time: 15:23:38\n",
      "NBClaPSPSifier Model miSS any PSrediction??? False\n"
     ]
    }
   ],
   "source": [
    "#training the claPSPSifier - 10000 tokenPS \n",
    "nb_10k_PS = NBClassifier(X_train_PS, y_train, '10000')\n",
    "nb_10k_PS.fit()\n",
    "\n",
    "#PSredicting the labelPS for tePSt PSamPSlePS\n",
    "y_pred_10k_PS = nb_10k_PS.predict(X_test_PS)\n",
    "  \n",
    "#Checking\n",
    "print(\"NBClaPSPSifier Model miSS any PSrediction???\", len(X_test) != len(y_pred_10k_PS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7ec8cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Correct Predictions: 2293\n",
      "Accuracy of the model: 2293 / 2928 = 0.7831 \n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "cor12, acc12 = nb_10k_PS.score(y_pred_10k_PS, y_test)\n",
    "print(\"Count of Correct Predictions:\", cor12)\n",
    "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor12, len(y_pred), acc12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9e995fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "#Caution: Execute only once to avoid duplications.\n",
    "storeResults('10k Tokens of Voab - Removed both Punctuation & Few Stopwords', cor12, acc12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "003e1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "results = pd.DataFrame({ 'Data Modification': attributes,    \n",
    "    'Correct Predictions': corr,\n",
    "    'Model Accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd0b0466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Modification</th>\n",
       "      <th>Correct Predictions</th>\n",
       "      <th>Model Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5k Tokens of Voab - Unprocessed Data</td>\n",
       "      <td>2332</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10k Tokens of Voab - Unprocessed Data</td>\n",
       "      <td>2332</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5k Tokens of Voab - Removed few Stopwords</td>\n",
       "      <td>2321</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10k Tokens of Voab - Removed few Stopwords</td>\n",
       "      <td>2321</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5k Tokens of Voab - No Punctuation Data</td>\n",
       "      <td>2309</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Removed few Stopwords</td>\n",
       "      <td>2300</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5k Tokens of Voab - Removed both Punctuation &amp;...</td>\n",
       "      <td>2296</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10k Tokens of Voab - Removed both Punctuation ...</td>\n",
       "      <td>2293</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unprocessed Data</td>\n",
       "      <td>2291</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10k Tokens of Voab - No Punctuation Data</td>\n",
       "      <td>2287</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Punctuation Data</td>\n",
       "      <td>2285</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Removed both Punctuation &amp; Few Stopwords</td>\n",
       "      <td>2283</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Data Modification  Correct Predictions  \\\n",
       "4                5k Tokens of Voab - Unprocessed Data                 2332   \n",
       "8               10k Tokens of Voab - Unprocessed Data                 2332   \n",
       "6           5k Tokens of Voab - Removed few Stopwords                 2321   \n",
       "10         10k Tokens of Voab - Removed few Stopwords                 2321   \n",
       "5             5k Tokens of Voab - No Punctuation Data                 2309   \n",
       "2                               Removed few Stopwords                 2300   \n",
       "7   5k Tokens of Voab - Removed both Punctuation &...                 2296   \n",
       "11  10k Tokens of Voab - Removed both Punctuation ...                 2293   \n",
       "0                                    Unprocessed Data                 2291   \n",
       "9            10k Tokens of Voab - No Punctuation Data                 2287   \n",
       "1                                 No Punctuation Data                 2285   \n",
       "3            Removed both Punctuation & Few Stopwords                 2283   \n",
       "\n",
       "    Model Accuracy  \n",
       "4            0.796  \n",
       "8            0.796  \n",
       "6            0.793  \n",
       "10           0.793  \n",
       "5            0.789  \n",
       "2            0.786  \n",
       "7            0.784  \n",
       "11           0.783  \n",
       "0            0.782  \n",
       "9            0.781  \n",
       "1            0.780  \n",
       "3            0.780  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=['Model Accuracy', 'Correct Predictions'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43b51e",
   "metadata": {},
   "source": [
    "BERT for text sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e31c6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
